#!/usr/bin/env python3
# -*- coding: utf-8 -*-


import time

import rclpy
from rclpy.node import Node
from rclpy.qos import qos_profile_sensor_data  # ç›¸æœºå¸¸ç”¨ QoSï¼ˆBEST_EFFORTï¼‰

from geometry_msgs.msg import Twist
from sensor_msgs.msg import Image
from std_msgs.msg import Bool
from cv_bridge import CvBridge

import cv2
import mediapipe as mp


class GestureController(Node):
    def __init__(self):
        super().__init__('gesture_controller')

        # --- å‚æ•° ---
        self.image_topic = self.declare_parameter(
            'image_topic', '/camera/color/image_raw'  # è§†ä½ çš„ç³»ç»Ÿå¯æ”¹ä¸º /camera/camera/color/image_raw
        ).get_parameter_value().string_value
        self.enable_viz = self.declare_parameter('enable_viz', True).get_parameter_value().bool_value
        self.enable_cmd_vel = self.declare_parameter('enable_cmd_vel', False).get_parameter_value().bool_value

        # é”å­˜ç›¸å…³å‚æ•°
        self.latch_enabled = self.declare_parameter('latch_enabled', True).get_parameter_value().bool_value
        self.latched_state = self.declare_parameter('latched_initial', False).get_parameter_value().bool_value  # å¯åŠ¨é»˜è®¤ False=åœ
        self.idle_auto_stop_ms = float(self.declare_parameter('idle_auto_stop_ms', 0).get_parameter_value().integer_value)
        # idle_auto_stop_ms=0 è¡¨ç¤ºç¦ç”¨â€œæ— æ‰‹è¶…æ—¶è‡ªåŠ¨åœâ€ï¼›å¦åˆ™è¶…è¿‡è¯¥æ¯«ç§’æ²¡çœ‹åˆ°æ‰‹å°±å¼ºåˆ¶ False

        # --- å‘å¸ƒå™¨ ---
        self.pub_cmd = self.create_publisher(Twist, '/cmd_vel', 10)
        self.pub_flag = self.create_publisher(Bool, '/forward_or_stop', 10)
        self.pub_use_gesture = self.create_publisher(Bool, '/use_gesture', 10)

        # --- è®¢é˜…å›¾åƒï¼ˆç›¸æœº QoSï¼‰ ---
        self.sub_img = self.create_subscription(Image, self.image_topic, self.image_cb, qos_profile_sensor_data)

        # --- CvBridge & MediaPipe ---
        self.bridge = CvBridge()
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            max_num_hands=1,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5,
        )
        self.mp_draw = mp.solutions.drawing_utils

        # è®°å½•æœ€è¿‘ä¸€æ¬¡çœ‹åˆ°æ‰‹çš„æ—¶é—´
        self.last_hand_seen_ts = time.monotonic()

        self.get_logger().info(
            f"GestureController started. Subscribing: {self.image_topic} | viz={self.enable_viz} "
            f"| enable_cmd_vel={self.enable_cmd_vel} | latch={self.latch_enabled} "
            f"| init_state={self.latched_state} | idle_auto_stop_ms={self.idle_auto_stop_ms}"
        )

    # ----------------- å›¾åƒå›è°ƒ -----------------
    def image_cb(self, msg: Image):
        try:
            frame = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
        except Exception as e:
            self.get_logger().warn(f'cv_bridge è½¬æ¢å¤±è´¥: {e}')
            return

        # é•œåƒç¿»è½¬ï¼ˆæ›´ç¬¦åˆäººé¢å¯¹æ‘„åƒå¤´çš„ç›´è§‰ï¼‰
        frame = cv2.flip(frame, 1)
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.hands.process(rgb_frame)

        # å…ˆæŠŠâ€œå°†è¦å‘å¸ƒâ€çš„çŠ¶æ€è®¾ä¸ºâ€œå½“å‰é”å­˜çŠ¶æ€â€
        current_state = bool(self.latched_state)
        cmd = Twist()
        used_gesture = False
        detected_hand = False

        # â€”â€” æ‰‹åŠ¿è¯†åˆ« â€”â€”ï¼ˆåªå¤„ç†ä¸€åªæ‰‹ï¼‰
        if results.multi_hand_landmarks:
            detected_hand = True
            self.last_hand_seen_ts = time.monotonic()

            for hand_landmarks in results.multi_hand_landmarks:
                # ç”»å…³é”®ç‚¹ï¼ˆå¯é€‰ï¼‰
                self.mp_draw.draw_landmarks(frame, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)

                # æŒ‡å°–ç´¢å¼•ï¼ˆå‚ç…§ MediaPipe Handsï¼‰
                tip_ids = [4, 8, 12, 16, 20]
                fingers_up = []

                # æ‹‡æŒ‡ï¼ˆæ°´å¹³åˆ¤æ–­ï¼‰â€”â€”å·¦å³æ‰‹/é•œåƒå¯èƒ½éœ€è¦ä¾åœºæ™¯è°ƒæ•´
                fingers_up.append(hand_landmarks.landmark[tip_ids[0]].x < hand_landmarks.landmark[tip_ids[0] - 2].x)

                # å…¶ä½™ 4 æŒ‡ï¼ˆç«–ç›´åˆ¤æ–­ï¼‰
                for i in range(1, 5):
                    fingers_up.append(hand_landmarks.landmark[tip_ids[i]].y < hand_landmarks.landmark[tip_ids[i] - 2].y)

                total_fingers = fingers_up.count(True)

                # === æ‰‹åŠ¿ â†’ çŠ¶æ€å˜æ›´ï¼ˆä»…å¯¹ âœŠ / ğŸ– ç”Ÿæ•ˆï¼›å…¶å®ƒæ‰‹åŠ¿ä¸æ”¹å˜é”å­˜ï¼‰ ===
                if total_fingers == 0:
                    # âœŠ Fist â†’ å‰è¿›(True)
                    if self.latch_enabled:
                        self.latched_state = True
                        current_state = True
                    else:
                        current_state = True
                    used_gesture = True
                    if self.enable_cmd_vel:
                        cmd.linear.x = 0.3
                    self.get_logger().info("âœŠ Fist â†’ forward (latched=True)")
                elif total_fingers == 5:
                    # ğŸ– Open palm â†’ åœæ­¢(False)
                    if self.latch_enabled:
                        self.latched_state = False
                        current_state = False
                    else:
                        current_state = False
                    used_gesture = True
                    if self.enable_cmd_vel:
                        cmd.linear.x = 0.0
                        cmd.angular.z = 0.0
                    self.get_logger().info("ğŸ– Open palm â†’ stop (latched=False)")
                else:
                    # å…¶å®ƒ/æœªçŸ¥ â†’ ä¸æ”¹é”å­˜ï¼›åªæ‰“å°
                    self.get_logger().info("âœ‹ Other/unknown â†’ keep last state")
                break  # å•æ‰‹å°±å¤Ÿäº†

        # â€”â€” æ— æ‰‹å¯è§æ—¶çš„å¤„ç†ï¼šä¿æŒé”å­˜ï¼›å¯é€‰è¶…æ—¶è‡ªåŠ¨åœ â€”â€” 
        if not detected_hand and self.idle_auto_stop_ms > 0:
            dt_ms = (time.monotonic() - self.last_hand_seen_ts) * 1000.0
            if dt_ms >= self.idle_auto_stop_ms:
                if self.latch_enabled:
                    if self.latched_state:  # åªæœ‰åœ¨å½“å‰æ˜¯ True æ—¶æ‰“å°ä¸€æ¬¡
                        self.get_logger().warn(f"No hand for {dt_ms:.0f}ms â†’ auto stop")
                    self.latched_state = False
                current_state = False

        # å‘å¸ƒ forward_or_stopï¼ˆBoolï¼‰â€”â€” å§‹ç»ˆå‘å¸ƒâ€œå½“å‰é”å­˜/è®¡ç®—åçš„çŠ¶æ€â€
        self.pub_flag.publish(Bool(data=bool(current_state)))
        # â€œæ­£åœ¨ç”¨æ‰‹åŠ¿æ§åˆ¶â€çš„æ ‡å¿—ï¼ˆå¯é€‰ï¼‰
        # self.pub_use_gesture.publish(Bool(data=used_gesture))

        # å¯é€‰å‘å¸ƒ /cmd_velï¼ˆé»˜è®¤å…³é—­ï¼‰
        # if self.enable_cmd_vel:
        #     self.pub_cmd.publish(cmd)

        # å¯è§†åŒ–
        if self.enable_viz:
            try:
                cv2.imshow('Gesture Controller (RealSense topic)', frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    rclpy.shutdown()
            except cv2.error:
                # æ— æ˜¾ç¤ºç¯å¢ƒæ—¶è‡ªåŠ¨å…³é—­å¯è§†åŒ–
                self.enable_viz = False

    def destroy_node(self):
        try:
            self.hands.close()
        except Exception:
            pass
        try:
            cv2.destroyAllWindows()
        except Exception:
            pass
        super().destroy_node()

def main(args=None):
    rclpy.init(args=args)
    node = GestureController()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        if rclpy.ok():
            rclpy.shutdown()


if __name__ == '__main__':
    main()
